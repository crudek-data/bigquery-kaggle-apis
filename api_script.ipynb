{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import kaggle\n",
    "from google.cloud import bigquery\n",
    "import db_dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Kaggle\n",
    "##### Setup\n",
    "1. Create a free Kaggle account\n",
    "2. Go to Settings\n",
    "3. Scroll down to the API section and select \"Create New Token\". This will download a kaggle.json file containing your API credentials\n",
    "   - For Windows place your file here: C:\\Users\\<Your Username>\\.kaggle\\kaggle.json\n",
    "\n",
    "##### Example Dataset\n",
    "1. We will use the popular [Iris Species](https://www.kaggle.com/datasets/uciml/iris) dataset\n",
    "   - Full url: https://www.kaggle.com/datasets/uciml/iris\n",
    "2. We will need two parts\n",
    "   - user who uploaded: uciml\n",
    "   - name of dataset: iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/uciml/iris\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'.\\\\dataset-metadata.json'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset identifier\n",
    "identifier = \"uciml/iris\"\n",
    "\n",
    "# automatically looks for kaggle json file in user directory\n",
    "kaggle.api.authenticate()\n",
    "\n",
    "# path to current directory and unzip is true in case of multiple files\n",
    "kaggle.api.dataset_download_files(identifier, path='.', unzip=True)\n",
    "\n",
    "# get metadata (optional)\n",
    "kaggle.api.dataset_metadata(identifier, path='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within our current directory we will now see all iris files on Kaggle along with a metadata json file. In this case, a csv and sqlite file. Most datasets from kaggle do not include a database file (sqlite), only a flat file (csv), which is why I include Step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv\n",
    "iris_df = pd.read_csv('iris.csv')\n",
    "iris_df.head()\n",
    "# iris_df.dtypes will need to check these for BQ write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Google BigQuery\n",
    "##### Setup\n",
    "1. Create a free GCP account\n",
    "2. [Create a BigQuery Service Account Key File](https://docs.aws.amazon.com/dms/latest/sbs/bigquery-redshift-migration-step-1.html#:~:text=On%20the%20Service%20accounts%20page,for%20downloads%20in%20your%20browser)\n",
    "   - place this json file in your current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for both BQ read/write\n",
    "\n",
    "# Setting environmental variable directly in your code\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = 'bq-crudek-data.json'\n",
    "\n",
    "# Initialize the BigQuery Client\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write\n",
    "- We will first write ```iris_df``` to our gcp project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoadJob<project=crudek-data, location=US, id=25562c58-6014-475f-b132-4fc739f4d171>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set table_id to the ID of the table to create\n",
    "# table_id = \"your-project.your_dataset.your_table_name\"\n",
    "table_id = 'crudek-data.practice_data.iris'\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[\n",
    "        # \"Species\" column uses pandas dtype \"object\", so its data type is ambiguous and cannot be auto-detected.\n",
    "        bigquery.SchemaField(\"Species\", bigquery.enums.SqlTypeNames.STRING),\n",
    "    ],\n",
    "    # by default it appends the data. We can optionally change this with write_disposition \n",
    "    #write_disposition=\"WRITE_TRUNCATE\",\n",
    ")\n",
    "\n",
    "# Make API request\n",
    "job = client.load_table_from_dataframe(\n",
    "    iris_df, table_id, job_config=job_config\n",
    ")  \n",
    "# Wait for the job to complete.\n",
    "job.result()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 300 rows and 6 columns to crudek-data.practice_data.iris\n"
     ]
    }
   ],
   "source": [
    "# confirm with shape\n",
    "table = client.get_table(table_id)\n",
    "print(\n",
    "    \"Loaded {} rows and {} columns to {}\".format(\n",
    "        table.num_rows, len(table.schema), table_id\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read\n",
    "- Now that ```iris_df``` is loaded in to BigQuery, we can query it with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
       "0  99            5.1           2.5            3.0           1.1   \n",
       "1  61            5.0           2.0            3.5           1.0   \n",
       "2  80            5.7           2.6            3.5           1.0   \n",
       "3  63            6.0           2.2            4.0           1.0   \n",
       "4  93            5.8           2.6            4.0           1.2   \n",
       "\n",
       "           Species  \n",
       "0  Iris-versicolor  \n",
       "1  Iris-versicolor  \n",
       "2  Iris-versicolor  \n",
       "3  Iris-versicolor  \n",
       "4  Iris-versicolor  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write the SQL query\n",
    "sql_query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM `crudek-data.practice_data.iris` \n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "# Make an API request. \n",
    "query_job = client.query(\n",
    "    sql_query)\n",
    "\n",
    "# retreive and convert the result to a Pandas DataFrame\n",
    "iris_df_2 = query_job.to_dataframe()\n",
    "\n",
    "# Display the DataFrame\n",
    "iris_df_2.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
